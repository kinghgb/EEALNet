# EEALNet
Camouflaged Object Detection (COD) focuses on identifying objects that are seamlessly blended into complex backgrounds, where the primary challenge arises from the high similarity in texture and color between the object and its surroundings, leading to ambiguous visual cues and difficult segmentation.  Drawing inspiration from the human visual systemâ€™s coarse-to-fine perception mechanism, we propose a novel two-stage framework, termed Coarse to Fine, and develop a corresponding network architecture, EEALNet, to effectively address these challenges. In the initial coarse localization stage, we introduce a Mirror Fusion Module(MFM) that utilizes a mirror-symmetric fusion strategy to integrate deep semantic information with spatially detailed shallow features, thereby restoring fine-grained spatial details often diminished in deeper layers.  Subsequently, in the fine segmentation stage, an Edge-Guided Refinement Module (EGRM) is devised to iteratively enhance discrimination between object interiors and boundaries, focusing alternately on foreground regions and contour information.  To further improve segmentation robustness, especially along ambiguous boundaries, morphological operations such as dilation and erosion are incorporated to adaptively expand attention regions around object edges.  Comprehensive experiments on four widely-used COD benchmarks demonstrate that our proposed EEALNet consistently surpasses state-of-the-art methods both quantitatively and qualitatively, validating its superior capability in accurately detecting camouflaged objects in challenging scenarios.
The full code will be published later
